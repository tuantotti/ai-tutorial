{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classifying news wires: a multiclass classification example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Reuters dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.datasets import reuters\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decoding news wires back to text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30979\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "print(len(word_index))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? japan's seasonally adjusted unemployment rate rose to a record 3 0 pct in january the worst since the government started compiling unemployment statistics under its current system in 1953 up from the previous record 2 9 pct in december the government's management and coordination agency said unemployment was up from 2 8 pct a year earlier unadjusted january unemployment totalled 1 82 mln people up from 1 61 mln in december and 1 65 mln a year earlier male unemployment in january remained at 2 9 pct equal to the second worst level set last december record male ? of 3 1 pct was set in july 1986 female unemployment in january remained at 3 0 pct equal to the record level marked in april august september and december last year january's record 3 0 pct unemployment rate mainly stemmed from loss of jobs in manufacturing industries particularly in export related firms due to the yen's continuing appreciation against the dollar officials said employment in manufacturing industries fell 380 000 from a year earlier to 14 30 mln including 1 83 mln employed in the textile industry down 190 000 from a year earlier and 1 06 mln in transport industries such as ? and shipbuilders down 170 000 reuter 3\n"
     ]
    }
   ],
   "source": [
    "reversed_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reversed_word_index.get(i - 3, '?') for i in X_train[200]])\n",
    "print(decoded_newswire)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "\n",
    "X_train_vectorize = vectorize_sequences(X_train)\n",
    "X_test_vectorize = vectorize_sequences(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n",
      "10000\n",
      "8982\n",
      "[ 3  4  3 ... 25  3 25]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vectorize)\n",
    "print(len(X_train_vectorize[0]))\n",
    "print(len(X_train_vectorize))\n",
    "print(y_train)\n",
    "# print(y_train[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[ 3 10  1 ...  3  3 24]\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "#\n",
    "# dimension = Counter(y_train)\n",
    "# print(len(dimension))\n",
    "def to_one_hot(labels, _dimension=46):\n",
    "    results = np.zeros((len(labels), _dimension))\n",
    "    for index, value in enumerate(labels):\n",
    "        results[index, value] = 1.\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "y_train_one_hot = to_one_hot(y_train)\n",
    "print(y_train_one_hot)\n",
    "y_test_one_hot = to_one_hot(y_test)\n",
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Use to_categorical method in keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_one_hot_lib = to_categorical(y_train, num_classes=46)\n",
    "y_test_one_hot_lib = to_categorical(y_test, num_classes=46)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equal(y_train_one_hot, y_train_one_hot_lib))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building the network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.activations import softmax, relu\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import Accuracy\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    _model = Sequential()\n",
    "    _model.add(Dense(64, activation=relu, input_shape=(10000,)))\n",
    "    _model.add(Dense(64, activation=relu))\n",
    "    _model.add(Dense(46, activation=softmax))\n",
    "\n",
    "    _model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    _model.summary()\n",
    "    return _model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compile the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                640064    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 46)                2990      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 2s 51ms/step - loss: 2.7448 - accuracy: 0.4723 - val_loss: 1.9504 - val_accuracy: 0.5840\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.5852 - accuracy: 0.6610 - val_loss: 1.5078 - val_accuracy: 0.6796\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2220 - accuracy: 0.7360 - val_loss: 1.3188 - val_accuracy: 0.7241\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.9903 - accuracy: 0.7877 - val_loss: 1.1785 - val_accuracy: 0.7430\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8140 - accuracy: 0.8285 - val_loss: 1.1064 - val_accuracy: 0.7542\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6709 - accuracy: 0.8566 - val_loss: 1.0387 - val_accuracy: 0.7809\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5592 - accuracy: 0.8831 - val_loss: 1.0153 - val_accuracy: 0.7898\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4654 - accuracy: 0.9026 - val_loss: 0.9893 - val_accuracy: 0.7875\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3921 - accuracy: 0.9157 - val_loss: 0.9802 - val_accuracy: 0.7909\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3338 - accuracy: 0.9282 - val_loss: 0.9441 - val_accuracy: 0.8053\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2870 - accuracy: 0.9383 - val_loss: 0.9662 - val_accuracy: 0.7820\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2522 - accuracy: 0.9430 - val_loss: 0.9408 - val_accuracy: 0.8087\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2223 - accuracy: 0.9470 - val_loss: 0.9475 - val_accuracy: 0.8031\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2028 - accuracy: 0.9510 - val_loss: 0.9830 - val_accuracy: 0.7998\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1793 - accuracy: 0.9532 - val_loss: 1.0426 - val_accuracy: 0.7842\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1689 - accuracy: 0.9529 - val_loss: 0.9524 - val_accuracy: 0.7998\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1581 - accuracy: 0.9552 - val_loss: 1.0172 - val_accuracy: 0.7953\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1453 - accuracy: 0.9551 - val_loss: 0.9920 - val_accuracy: 0.8031\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1373 - accuracy: 0.9593 - val_loss: 1.0482 - val_accuracy: 0.7920\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1309 - accuracy: 0.9577 - val_loss: 1.0765 - val_accuracy: 0.7898\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2216e3b0dc0>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = build_model()\n",
    "checkpoint_filepath = './best_model/multi_weights.{epoch:02d}-{val_accuracy:.2f}.h5'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(X_train_vectorize, y_train_one_hot_lib, epochs=20, batch_size=512, validation_split=0.1,\n",
    "          callbacks=[model_checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at multi_weights.{epoch:02d}-{val_loss:.2f}.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19708/4259892039.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mbest_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcheckpoint_filepath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\legacy\\save.py\u001B[0m in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[0;32m    225\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_str\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_str\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 227\u001B[1;33m                         raise IOError(\n\u001B[0m\u001B[0;32m    228\u001B[0m                             \u001B[1;34mf\"No file or directory found at {filepath_str}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m                         )\n",
      "\u001B[1;31mOSError\u001B[0m: No file or directory found at multi_weights.{epoch:02d}-{val_loss:.2f}.hdf5"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "best_model = load_model(checkpoint_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
