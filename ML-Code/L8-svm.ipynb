{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== Nguồn http://users.soict.hust.edu.vn/khoattq/ml-dm-course/ ======\n",
    "\n",
    "\n",
    "# Bài toán phân loại sử dụng SVM \n",
    "\n",
    "Mục tiêu: \n",
    "- Xây dựng được mô hình svm sử dụng thư viện sklearn. \n",
    "- Ứng dụng, hiểu cách áp dụng mô hình SVM vào giải quyết bài toán thực tế (Ví dụ: phân loại văn bản) \n",
    "- Sử dụng độ đo Accuracy để làm độ đo đánh giá chất lượng mô hình. \n",
    "\n",
    "Dữ liệu: \n",
    "- Có tập các văn bản và nhãn tương ứng của từng văn bản trong một khoảng thời gian \n",
    "- Tập các nhãn (10 nhãn khác nhau): \n",
    "    > Giải trí, Khoa học - Công nghệ, Kinh tế, Pháp luật, Sức khỏe, Thể thao, Thời sự, Tin khác, Độc giả, Đời sống - Xã hội\n",
    "- Ví dụ văn bản nhãn **thể thao**: \n",
    "    > \"Dân_trí Real Madrid đã dẫn trước trong cả trận đấu , nhưng họ vẫn phải chấp_nhận bị Dortmund cầm hòa 2-2 ở Bernabeu . Real Madrid chấp_nhận đứng thứ_hai ở bảng F Champions League ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dữ liệu từ thư mục đã thu thập từ trước \n",
    "\n",
    "Giả sử cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_1135/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng văn bản    Nhãn                          \n",
      "---------------------------------------------\n",
      "120                 doi-song                      \n",
      "54                  du-lich                       \n",
      "201                 giai-tri                      \n",
      "105                 giao-duc                      \n",
      "144                 khoa-hoc                      \n",
      "262                 kinh-doanh                    \n",
      "59                  phap-luat                     \n",
      "162                 suc-khoe                      \n",
      "173                 the-thao                      \n",
      "59                  thoi-su                       \n",
      "---------------------------------------------\n",
      "Tổng số văn bản: 1339\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"data/news_vnexpress/\"\n",
    "header = \"%-20s%-30s\" % (\"Số lượng văn bản\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "total = 0\n",
    "for label in os.listdir(DATA_PATH):\n",
    "    n = len(os.listdir(os.path.join(DATA_PATH, label)))\n",
    "    total += n\n",
    "    entry = \"%-20d%-30s\" % (n, label)\n",
    "    print(entry)\n",
    "print(\"---------------------------------------------\")\n",
    "print(f'Tổng số văn bản: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'filenames', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "data_train = load_files(container_path=DATA_PATH, encoding=\"utf-8\")\n",
    "print(dir(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID     Nhãn      \n",
      "---------------------------------------------\n",
      "0      doi-song  \n",
      "1      du-lich   \n",
      "2      giai-tri  \n",
      "3      giao-duc  \n",
      "4      khoa-hoc  \n",
      "5      kinh-doanh\n",
      "6      phap-luat \n",
      "7      suc-khoe  \n",
      "8      the-thao  \n",
      "9      thoi-su   \n"
     ]
    }
   ],
   "source": [
    "header = \"%-6s %-10s\" % (\"ID\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "for id, label in enumerate(data_train.target_names):\n",
    "    print(\"%-6d %-10s\" % (id, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mời độc giả đặt câu hỏi tại đây\\n', '(Nguồn và ảnh: Trung tâm cấy tóc New Hair)\\n']\n",
      "\n",
      "['data/news_vnexpress/khoa-hoc\\\\00133.txt'\n",
      " 'data/news_vnexpress/suc-khoe\\\\00102.txt']\n",
      "\n",
      "[4 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_train.data[0:2], end='\\n\\n')\n",
    "print(data_train.filenames[0:2], end='\\n\\n')\n",
    "print(data_train.target[0:2], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Bài tập\\n - Kiểm tra các thông tin sau:\\n    + Số lượng văn bản trong data_train.data\\n    + Số lượng ids trong data_train.target\\n    + Số lượng filenames trong data_train.filenames\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bài tập\n",
    " - Kiểm tra các thông tin sau:\n",
    "    + Số lượng văn bản trong data_train.data\n",
    "    + Số lượng ids trong data_train.target\n",
    "    + Số lượng filenames trong data_train.filenames\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tiền xử lý dữ liệu: đưa dữ liệu từ dạng text về dạng ma trận bằng TF-IDF\n",
    "\n",
    "- Thử nghiệm để kiểm tra hoạt động chuyển hoá dữ liệu về dạng ma trận "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số lượng từ dừng: 2063\n",
      "Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại):  ['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
      "\n",
      "5 từ đầu tiên trong từ điển:\n",
      "\n",
      "1 :  ('mời', 7462)\n",
      "2 :  ('độc', 12711)\n",
      "3 :  ('giả', 4378)\n",
      "4 :  ('câu', 3084)\n",
      "5 :  ('ảnh', 12756)\n",
      "6 :  ('trung', 11017)\n",
      "\n",
      "Số chiều của dữ liệu: (1339, 12796)\n",
      "Số từ trong từ điển: 12796\n"
     ]
    }
   ],
   "source": [
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords]\n",
    "print(f\"Tổng số lượng từ dừng: {len(stopwords)}\")\n",
    "print(\"Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại): \", stopwords[:10])\n",
    "print()\n",
    "\n",
    "\"\"\"\n",
    "Chuyển hoá dữ liệu text về dạng vector tfidf \n",
    "    - loại bỏ từ dừng\n",
    "    - sinh từ điển\n",
    "    - chuyển thành dữ liệu dạng ma trận 2 chiều kích thước n x m với n là số lượng văn bản và m là số lượng từ trong từ điển\n",
    "\"\"\"\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "print(\"5 từ đầu tiên trong từ điển:\\n\")\n",
    "i = 0\n",
    "for k,v in module_count_vector.vocabulary_.items():\n",
    "    i+=1\n",
    "    print(i, \": \", (k, v))\n",
    "    if i > 5:\n",
    "        break \n",
    "print()\n",
    "\n",
    "# Số chiều của dữ liệu \n",
    "print(f\"Số chiều của dữ liệu: {data_preprocessed.shape}\")\n",
    "print(f\"Số từ trong từ điển: {len(module_count_vector.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia dữ liệu thành 2 phần train_data và test_data\n",
    "- train_data chiếm 80 % dữ liệu \n",
    "- test_data chiếm 20 % dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu training =  (1071, 12796) (1071,)\n",
      "Dữ liệu testing =  (268, 12796) (268,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# chia dữ liệu thành 2 phần sử dụng hàm train_test_split.\n",
    "test_size = 0.2\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split( data_preprocessed, data_train.target, test_size=test_size)\n",
    "\n",
    "\n",
    "# hiển thị một số thông tin về dữ liệu \n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Bài tập\\n - Hiển thị ra id, tên nhãn của 5 văn bản đầu tiên trong tập train. \\n - Gợi ý: lấy dữ liệu id từ biến y_train, mapping với thứ tự nằm trong mảng data_train.target_names\\n'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bài tập\n",
    " - Hiển thị ra id, tên nhãn của 5 văn bản đầu tiên trong tập train. \n",
    " - Gợi ý: lấy dữ liệu id từ biến y_train, mapping với thứ tự nằm trong mảng data_train.target_names\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Huấn luyện mô hình SVM trên tập train_data\n",
    "\n",
    "Sử dụng thư viện sklearn để xây dựng mô hình \n",
    "- `svm.SVC(kernel='linear', C=1.0)`: chọn hàm nhân phân tách là linear, tham số C=1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training ...\n",
      "- Train size = (1071, 12796)\n",
      "- model - train complete\n"
     ]
    }
   ],
   "source": [
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Đánh giá mô hình SVM trên tập test_data\n",
    "\n",
    "Thực hiện dự đoán nhãn cho từng văn bản trong tập test_data \n",
    "\n",
    "Độ đo đánh giá: \n",
    "> accuracy = tổng số văn bản dự đoán đúng  / tổng số văn bản có trong tập test_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Testing ...\n",
      "- Acc = 0.9104477611940298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng model đã được huấn luyện để phán đoán 1 văn bản mới \n",
    "- Dữ liệu mới đến ở dạng dữ liệu thô => cần tiền xử lý dữ liệu về dạng dữ_liệu_ma_trận\n",
    "- Phán đoán bằng hàm model.predict(dữ_liệu_ma_trận) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4284)\t0.6630365788571639\n",
      "  (0, 2045)\t0.7485869990170734\n",
      "\n",
      "[8] the-thao\n"
     ]
    }
   ],
   "source": [
    "# tiền xử lý dữ liệu sử dụng module model_rf_preprocess. \n",
    "news = [\"Công_phượng ghi bàn cho đội_tuyển Việt_nam\"]\n",
    "preprocessed_news = model_rf_preprocess.transform(news)\n",
    "print(preprocessed_news, end='\\n\\n')\n",
    "# phán đoán nhãn\n",
    "pred = model.predict(preprocessed_news)\n",
    "print(pred, data_train.target_names[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bài tập bổ sung: \n",
    "\n",
    "### 4.1 Thử nghiệm các tham số \n",
    "\n",
    "- Các tham số với giá trị khác nhau có thể ảnh hưởng để kết quả học \n",
    "- Cần thử nghiệm kỹ lượng để đưa ra kết quả khách quan: tham số C, kernel.\n",
    "    - Chọn mô hình với bộ tham số cho kết quả tốt nhất "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"Bài tập\\n - Đánh giá các tham số của mô hình SVM: kernel, C\\n - Gợi ý:\\n     + Đầu tiên cố định C = 1.0 (có thể là giá trị khác), thay đổi kernel = {'linear', 'poly', 'rbf', 'sigmoid'}\\n     + Với mỗi kernel chạy huấn luyện và đánh giá lại mô hình. Chọn kernel cho acc cao nhất.\\n       Giả sử trong trường hợp này là linear\\n     + Cố định kernel là linear, thay đổi C = {0.1, 1.0, 5.0, 10.0}\\n     + Với mỗi giá trị C chạy huấn luện và đánh giá lại. Chọn C cho acc cao nhất.\\n\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM: kernel, C\n",
    " - Gợi ý:\n",
    "     + Đầu tiên cố định C = 1.0 (có thể là giá trị khác), thay đổi kernel = {'linear', 'poly', 'rbf', 'sigmoid'}\n",
    "     + Với mỗi kernel chạy huấn luyện và đánh giá lại mô hình. Chọn kernel cho acc cao nhất.\n",
    "       Giả sử trong trường hợp này là linear\n",
    "     + Cố định kernel là linear, thay đổi C = {0.1, 1.0, 5.0, 10.0}\n",
    "     + Với mỗi giá trị C chạy huấn luện và đánh giá lại. Chọn C cho acc cao nhất.\n",
    "\"\"\"\n",
    "######################\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Phân loại số viết tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu training =  (1437, 64) (1437,)\n",
      "Dữ liệu testing =  (360, 64) (360,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "target = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=test_size)\n",
    "\n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training ...\n",
      "- Train size = (1437, 64)\n",
      "- model - train complete\n",
      "- Testing ...\n",
      "- Acc = 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM với bài toán phân loại ảnh\n",
    " - Gợi ý: Làm tương tự với phân loại văn bản phía trên\n",
    "\"\"\"\n",
    "######################\n",
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
